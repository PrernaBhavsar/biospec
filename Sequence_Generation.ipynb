{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7fb90015bb9d4ab6b72dfe655dafaffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78d0ee724a4a4322892c0b285723b77a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5a22af0a33054971bc65b35dbc12ff80",
              "IPY_MODEL_ae33df0336444d928b44e4d5328a490e"
            ]
          }
        },
        "78d0ee724a4a4322892c0b285723b77a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a22af0a33054971bc65b35dbc12ff80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_ee4087581bc94d61bd943945c2624995",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb4745ca61494b55ab961303ce1b8fab"
          }
        },
        "ae33df0336444d928b44e4d5328a490e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1d481c2633cc4b44a210de0bb956264a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f324a890a1d4508b4e9beb0e857f3d4"
          }
        },
        "ee4087581bc94d61bd943945c2624995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb4745ca61494b55ab961303ce1b8fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d481c2633cc4b44a210de0bb956264a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f324a890a1d4508b4e9beb0e857f3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanmaylaud/biospec/blob/main/Sequence_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DYo3KkMJ4B4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88bfae7-411c-4696-f72a-af500dab62be"
      },
      "source": [
        "!pip install -q wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8MB 34.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 53.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 14.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 51.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz5v5DTX1IHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c48d5a-8480-4da0-a06f-d5dffb4edc6c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCIRUEzf0XeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91785f90-353a-40e3-b95d-fa77766a4cfd"
      },
      "source": [
        "%cd '/content/drive/MyDrive/CSE291C00/Stage_1_Analysis_29_tissues_Project/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CSE291C00/Stage_1_Analysis_29_tissues_Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v6I7i-C0pFp"
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4VRi3gqcxG1"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxFbGgiu2Ax5"
      },
      "source": [
        "import pickle\n",
        "with open('stomach_merged_large.pickle','rb') as f:\n",
        "    merged = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV8kC_t6Ro5p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "53953edd-f9fb-439e-b655-85be1d587983"
      },
      "source": [
        "merged"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scan_id</th>\n",
              "      <th>PrecursorCharge</th>\n",
              "      <th>parent mass</th>\n",
              "      <th>Peptide</th>\n",
              "      <th>Protein</th>\n",
              "      <th>spectrum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3168</td>\n",
              "      <td>4</td>\n",
              "      <td>1437.74</td>\n",
              "      <td>R.EDSQRPGAHLTVK.K</td>\n",
              "      <td>tr|F8VYN5|F8VYN5_HUMAN</td>\n",
              "      <td>(0, 52)\\t0.017556602135300636\\n  (0, 56)\\t0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3073</td>\n",
              "      <td>3</td>\n",
              "      <td>1078.59</td>\n",
              "      <td>R.EDSQRPGAHLTVK.K</td>\n",
              "      <td>tr|F8VYN5|F8VYN5_HUMAN</td>\n",
              "      <td>(0, 29)\\t0.2808007597923279\\n  (0, 31)\\t0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6771</td>\n",
              "      <td>3</td>\n",
              "      <td>1079.60</td>\n",
              "      <td>K.ALVNQLHER.V</td>\n",
              "      <td>tr|D6R9R1|D6R9R1_HUMAN</td>\n",
              "      <td>(0, 27)\\t0.00489127216860652\\n  (0, 29)\\t0.4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17822</td>\n",
              "      <td>3</td>\n",
              "      <td>1085.67</td>\n",
              "      <td>R.(C,57.021)IIPSVIKR.A</td>\n",
              "      <td>tr|G3V524|G3V524_HUMAN</td>\n",
              "      <td>(0, 29)\\t0.5876671075820923\\n  (0, 30)\\t0.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3752</td>\n",
              "      <td>3</td>\n",
              "      <td>1087.53</td>\n",
              "      <td>Y.VNDAFGTAHR.A</td>\n",
              "      <td>sp|P00558|PGK1_HUMAN</td>\n",
              "      <td>(0, 27)\\t0.006831302773207426\\n  (0, 28)\\t0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9244</th>\n",
              "      <td>32033</td>\n",
              "      <td>2</td>\n",
              "      <td>2564.17</td>\n",
              "      <td>K.GTWIHPEIDNPEYSPDPSIYAY.D</td>\n",
              "      <td>tr|K7EL50|K7EL50_HUMAN</td>\n",
              "      <td>(0, 132)\\t0.026059379801154137\\n  (0, 135)\\t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9245</th>\n",
              "      <td>32281</td>\n",
              "      <td>2</td>\n",
              "      <td>2564.17</td>\n",
              "      <td>K.GTWIHPEIDNPEYSPDPSIYAY.D</td>\n",
              "      <td>tr|K7EL50|K7EL50_HUMAN</td>\n",
              "      <td>(0, 161)\\t0.03084501251578331\\n  (0, 163)\\t0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9246</th>\n",
              "      <td>47874</td>\n",
              "      <td>3</td>\n",
              "      <td>3847.89</td>\n",
              "      <td>-.NVEDIELWLYEVEGHLASDDYGKDLTNVQNLQK.-</td>\n",
              "      <td>sp|Q13813|SPTN1_HUMAN</td>\n",
              "      <td>(0, 225)\\t0.007571768946945667\\n  (0, 280)\\t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9247</th>\n",
              "      <td>30234</td>\n",
              "      <td>2</td>\n",
              "      <td>2568.17</td>\n",
              "      <td>K.(G,3.999)TWIHPEIDNPEYSPDPSIYAY.D</td>\n",
              "      <td>tr|K7EL50|K7EL50_HUMAN</td>\n",
              "      <td>(0, 135)\\t0.022118493914604187\\n  (0, 157)\\t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9248</th>\n",
              "      <td>46513</td>\n",
              "      <td>3</td>\n",
              "      <td>3879.87</td>\n",
              "      <td>R.NVEDIEL(W,31.993)LYEVEGHLASDDYGKDLTNVQNLQK.K</td>\n",
              "      <td>tr|A0A0D9SGF6|A0A0D9SGF6_HUMAN</td>\n",
              "      <td>(0, 308)\\t0.03400345891714096\\n  (0, 408)\\t0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>277654 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     scan_id  ...                                           spectrum\n",
              "0       3168  ...    (0, 52)\\t0.017556602135300636\\n  (0, 56)\\t0....\n",
              "1       3073  ...    (0, 29)\\t0.2808007597923279\\n  (0, 31)\\t0.00...\n",
              "2       6771  ...    (0, 27)\\t0.00489127216860652\\n  (0, 29)\\t0.4...\n",
              "3      17822  ...    (0, 29)\\t0.5876671075820923\\n  (0, 30)\\t0.02...\n",
              "4       3752  ...    (0, 27)\\t0.006831302773207426\\n  (0, 28)\\t0....\n",
              "...      ...  ...                                                ...\n",
              "9244   32033  ...    (0, 132)\\t0.026059379801154137\\n  (0, 135)\\t...\n",
              "9245   32281  ...    (0, 161)\\t0.03084501251578331\\n  (0, 163)\\t0...\n",
              "9246   47874  ...    (0, 225)\\t0.007571768946945667\\n  (0, 280)\\t...\n",
              "9247   30234  ...    (0, 135)\\t0.022118493914604187\\n  (0, 157)\\t...\n",
              "9248   46513  ...    (0, 308)\\t0.03400345891714096\\n  (0, 408)\\t0...\n",
              "\n",
              "[277654 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlpwg1Jfcc6_",
        "outputId": "49de6719-364a-4234-d446-a5564a089b44"
      },
      "source": [
        "merged['Peptide'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "K.KYDEELEER.L                           689\n",
              "-.VGAHAGEYGAEALER.-                     614\n",
              "-.IQLVEEELDRAQER.-                      576\n",
              "-.SYELPDGQVITIGNER.-                    530\n",
              "-.TYFPHFDLSHGSAQVK.-                    503\n",
              "                                       ... \n",
              "Y.SGSTNYNPSL(K,0.943)SR.V                 1\n",
              "-.QSGESIDIITR.-                           1\n",
              "-.FSTSGLSISGL(N,0.984)PLPNPSYLLPPR.-      1\n",
              "K.RY(C,57.021)PNSVLVIIDVKPK.D             1\n",
              "K.GIIDPTKVV.R                             1\n",
              "Name: Peptide, Length: 77980, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sv9xNG5b1jy"
      },
      "source": [
        "def contains_number(x):\n",
        "  return any(char.isdigit() for char in x)\n",
        "\n",
        "merged['contains_num'] = merged['Peptide'].apply(contains_number)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "7UD3GVMScmPK",
        "outputId": "0dab63fd-1f1d-4497-e908-7da602e1258e"
      },
      "source": [
        "filtered = merged[~merged['contains_num']]\n",
        "filtered"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scan_id</th>\n",
              "      <th>PrecursorCharge</th>\n",
              "      <th>parent mass</th>\n",
              "      <th>Peptide</th>\n",
              "      <th>Protein</th>\n",
              "      <th>spectrum</th>\n",
              "      <th>contains_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3168</td>\n",
              "      <td>4</td>\n",
              "      <td>1437.74</td>\n",
              "      <td>R.EDSQRPGAHLTVK.K</td>\n",
              "      <td>tr|F8VYN5|F8VYN5_HUMAN</td>\n",
              "      <td>(0, 52)\\t0.017556602135300636\\n  (0, 56)\\t0....</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3073</td>\n",
              "      <td>3</td>\n",
              "      <td>1078.59</td>\n",
              "      <td>R.EDSQRPGAHLTVK.K</td>\n",
              "      <td>tr|F8VYN5|F8VYN5_HUMAN</td>\n",
              "      <td>(0, 29)\\t0.2808007597923279\\n  (0, 31)\\t0.00...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6771</td>\n",
              "      <td>3</td>\n",
              "      <td>1079.60</td>\n",
              "      <td>K.ALVNQLHER.V</td>\n",
              "      <td>tr|D6R9R1|D6R9R1_HUMAN</td>\n",
              "      <td>(0, 27)\\t0.00489127216860652\\n  (0, 29)\\t0.4...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3752</td>\n",
              "      <td>3</td>\n",
              "      <td>1087.53</td>\n",
              "      <td>Y.VNDAFGTAHR.A</td>\n",
              "      <td>sp|P00558|PGK1_HUMAN</td>\n",
              "      <td>(0, 27)\\t0.006831302773207426\\n  (0, 28)\\t0....</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>16090</td>\n",
              "      <td>3</td>\n",
              "      <td>1087.62</td>\n",
              "      <td>-.LRVDPVNFK.-</td>\n",
              "      <td>sp|P02008|HBAZ_HUMAN</td>\n",
              "      <td>(0, 29)\\t0.580760657787323\\n  (0, 31)\\t0.052...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9241</th>\n",
              "      <td>36500</td>\n",
              "      <td>3</td>\n",
              "      <td>3837.66</td>\n",
              "      <td>V.SVNNEHNVANVDNNNGWDSWNSIWDYGNGFAATR.L</td>\n",
              "      <td>sp|Q9NS71|GKN1_HUMAN</td>\n",
              "      <td>(0, 226)\\t0.024037254974246025\\n  (0, 287)\\t...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9243</th>\n",
              "      <td>31837</td>\n",
              "      <td>2</td>\n",
              "      <td>2564.17</td>\n",
              "      <td>K.GTWIHPEIDNPEYSPDPSIYAY.D</td>\n",
              "      <td>tr|K7EL50|K7EL50_HUMAN</td>\n",
              "      <td>(0, 132)\\t0.03335380181670189\\n  (0, 135)\\t0...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9244</th>\n",
              "      <td>32033</td>\n",
              "      <td>2</td>\n",
              "      <td>2564.17</td>\n",
              "      <td>K.GTWIHPEIDNPEYSPDPSIYAY.D</td>\n",
              "      <td>tr|K7EL50|K7EL50_HUMAN</td>\n",
              "      <td>(0, 132)\\t0.026059379801154137\\n  (0, 135)\\t...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9245</th>\n",
              "      <td>32281</td>\n",
              "      <td>2</td>\n",
              "      <td>2564.17</td>\n",
              "      <td>K.GTWIHPEIDNPEYSPDPSIYAY.D</td>\n",
              "      <td>tr|K7EL50|K7EL50_HUMAN</td>\n",
              "      <td>(0, 161)\\t0.03084501251578331\\n  (0, 163)\\t0...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9246</th>\n",
              "      <td>47874</td>\n",
              "      <td>3</td>\n",
              "      <td>3847.89</td>\n",
              "      <td>-.NVEDIELWLYEVEGHLASDDYGKDLTNVQNLQK.-</td>\n",
              "      <td>sp|Q13813|SPTN1_HUMAN</td>\n",
              "      <td>(0, 225)\\t0.007571768946945667\\n  (0, 280)\\t...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151237 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     scan_id  ...  contains_num\n",
              "0       3168  ...         False\n",
              "1       3073  ...         False\n",
              "2       6771  ...         False\n",
              "4       3752  ...         False\n",
              "6      16090  ...         False\n",
              "...      ...  ...           ...\n",
              "9241   36500  ...         False\n",
              "9243   31837  ...         False\n",
              "9244   32033  ...         False\n",
              "9245   32281  ...         False\n",
              "9246   47874  ...         False\n",
              "\n",
              "[151237 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "0O-y_P0Y9YNL",
        "outputId": "22d50691-fe1f-4f1b-de48-9a3a33a3337e"
      },
      "source": [
        "filtered[filtered['parent mass'] <= 2050]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scan_id</th>\n",
              "      <th>PrecursorCharge</th>\n",
              "      <th>parent mass</th>\n",
              "      <th>Peptide</th>\n",
              "      <th>Protein</th>\n",
              "      <th>spectrum</th>\n",
              "      <th>contains_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3168</td>\n",
              "      <td>4</td>\n",
              "      <td>1437.74</td>\n",
              "      <td>R.EDSQRPGAHLTVK.K</td>\n",
              "      <td>tr|F8VYN5|F8VYN5_HUMAN</td>\n",
              "      <td>(0, 52)\\t0.017556602135300636\\n  (0, 56)\\t0....</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3073</td>\n",
              "      <td>3</td>\n",
              "      <td>1078.59</td>\n",
              "      <td>R.EDSQRPGAHLTVK.K</td>\n",
              "      <td>tr|F8VYN5|F8VYN5_HUMAN</td>\n",
              "      <td>(0, 29)\\t0.2808007597923279\\n  (0, 31)\\t0.00...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6771</td>\n",
              "      <td>3</td>\n",
              "      <td>1079.60</td>\n",
              "      <td>K.ALVNQLHER.V</td>\n",
              "      <td>tr|D6R9R1|D6R9R1_HUMAN</td>\n",
              "      <td>(0, 27)\\t0.00489127216860652\\n  (0, 29)\\t0.4...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3752</td>\n",
              "      <td>3</td>\n",
              "      <td>1087.53</td>\n",
              "      <td>Y.VNDAFGTAHR.A</td>\n",
              "      <td>sp|P00558|PGK1_HUMAN</td>\n",
              "      <td>(0, 27)\\t0.006831302773207426\\n  (0, 28)\\t0....</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>16090</td>\n",
              "      <td>3</td>\n",
              "      <td>1087.62</td>\n",
              "      <td>-.LRVDPVNFK.-</td>\n",
              "      <td>sp|P02008|HBAZ_HUMAN</td>\n",
              "      <td>(0, 29)\\t0.580760657787323\\n  (0, 31)\\t0.052...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8492</th>\n",
              "      <td>33263</td>\n",
              "      <td>2</td>\n",
              "      <td>2042.09</td>\n",
              "      <td>K.VFDEFKPLVEEPQNLIK.Q</td>\n",
              "      <td>tr|A0A087WWT3|A0A087WWT3_HUMAN</td>\n",
              "      <td>(0, 97)\\t0.024205707013607025\\n  (0, 109)\\t0...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8502</th>\n",
              "      <td>33290</td>\n",
              "      <td>2</td>\n",
              "      <td>2044.93</td>\n",
              "      <td>-.VFDEFKPLVEEPQNLIK.-</td>\n",
              "      <td>sp|P02768|ALBU_HUMAN</td>\n",
              "      <td>(0, 97)\\t0.03420107066631317\\n  (0, 109)\\t0....</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8503</th>\n",
              "      <td>33069</td>\n",
              "      <td>2</td>\n",
              "      <td>2045.11</td>\n",
              "      <td>-.VFDEFKPLVEEPQNLIK.-</td>\n",
              "      <td>sp|P02768|ALBU_HUMAN</td>\n",
              "      <td>(0, 97)\\t0.014191227033734322\\n  (0, 109)\\t0...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8505</th>\n",
              "      <td>35610</td>\n",
              "      <td>2</td>\n",
              "      <td>2046.07</td>\n",
              "      <td>K.VLGAFSDGLAHLDNLKGTFA.T</td>\n",
              "      <td>tr|A0A2R8Y7R2|A0A2R8Y7R2_HUMAN</td>\n",
              "      <td>(0, 96)\\t0.012251904234290123\\n  (0, 109)\\t0...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8506</th>\n",
              "      <td>40596</td>\n",
              "      <td>2</td>\n",
              "      <td>2045.93</td>\n",
              "      <td>-.VQYFWEALNNFTNEDR.-</td>\n",
              "      <td>sp|Q5T447|HECD3_HUMAN</td>\n",
              "      <td>(0, 109)\\t0.06464093178510666\\n  (0, 123)\\t0...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121001 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     scan_id  ...  contains_num\n",
              "0       3168  ...         False\n",
              "1       3073  ...         False\n",
              "2       6771  ...         False\n",
              "4       3752  ...         False\n",
              "6      16090  ...         False\n",
              "...      ...  ...           ...\n",
              "8492   33263  ...         False\n",
              "8502   33290  ...         False\n",
              "8503   33069  ...         False\n",
              "8505   35610  ...         False\n",
              "8506   40596  ...         False\n",
              "\n",
              "[121001 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2x4EdWQ7Umj"
      },
      "source": [
        "filtered = filtered[filtered['parent mass'] <= 2050]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URY2o9AZyPPG"
      },
      "source": [
        "filtered = filtered.sample(frac=1.0, random_state=SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neCSUfieeQh_",
        "outputId": "26062c3d-d00c-46a1-c292-3f97a6157dd5"
      },
      "source": [
        "def process_peptide(peptide):\n",
        "  result = \"\"\n",
        "  if '.' in peptide:\n",
        "    i = 0\n",
        "    while(peptide[i]) != '.':\n",
        "      i += 1\n",
        "    i+=1\n",
        "    while(peptide[i]) != '.':\n",
        "      result += peptide[i]\n",
        "      i+=1\n",
        "    return result   \n",
        "  else: \n",
        "    return peptide\n",
        "\n",
        "filtered['Peptide'].apply(process_peptide)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5436           SRVVGNPFDSK\n",
              "11669          LLEESLLSLIR\n",
              "5117             SFEMLILGR\n",
              "23665    ELTQDPAVSVALGQTVR\n",
              "2428             TSVLHVMVK\n",
              "               ...        \n",
              "9072            LQHPDMLVTK\n",
              "14213         NLDLDSIIAEVK\n",
              "4184          DIISDTSGDFRK\n",
              "9116       TDTSHHDQDHPTFNK\n",
              "15111        LVHPGVAEVVFVK\n",
              "Name: Peptide, Length: 121001, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-BTOjGSfrbT"
      },
      "source": [
        "filtered['Peptide'] = filtered['Peptide'].apply(process_peptide)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3ABpn4ZcykE",
        "outputId": "ec26a53d-ffe7-4959-b99f-54e4691c81d8"
      },
      "source": [
        "filtered['Peptide'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IQLVEEELDRAQER      809\n",
              "DSYVGDEAQSK         699\n",
              "KYDEELEER           682\n",
              "VGAHAGEYGAEALER     666\n",
              "TYFPHFDLSHGSAQVK    618\n",
              "                   ... \n",
              "RVHEEEDAGSQLIGFY      1\n",
              "SAWLSEKEDAVNK         1\n",
              "AGEIVVFKVEGR          1\n",
              "TALAMGADR             1\n",
              "LSSTQQSLAEK           1\n",
              "Name: Peptide, Length: 26127, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUPYhuuj10f3"
      },
      "source": [
        "filtered_distinct = filtered.drop_duplicates(subset=['Peptide'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY2atL2e4dfK",
        "outputId": "6fcf8c44-ac31-4ae4-b136-4b11678296eb"
      },
      "source": [
        "filtered_distinct['Peptide'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GLFISISDR             1\n",
              "SLADAINTEFK           1\n",
              "ISADSAIMNPASK         1\n",
              "LLVISGIPTHLDEGVVR     1\n",
              "ENDAVTIQVLNQLIQK      1\n",
              "                     ..\n",
              "KLTPEEEEILNK          1\n",
              "IQIPRPDDPSNQIK        1\n",
              "LLEMEEQAAFLVGSATPR    1\n",
              "IVPNVLLEQGK           1\n",
              "LSSTQQSLAEK           1\n",
              "Name: Peptide, Length: 26127, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUDr0VaRaoK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54894c42-fca9-426b-daa4-eaab3784df69"
      },
      "source": [
        "filtered_distinct['Peptide_Length'] = filtered_distinct['Peptide'].apply(lambda x: len(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mdkrubkaTM0"
      },
      "source": [
        "filtered_distinct = filtered_distinct.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IXunLSj8wBz",
        "outputId": "c87b0f13-baf6-4aa0-a188-5cac92b02cb4"
      },
      "source": [
        "from collections import defaultdict\n",
        "distribution = defaultdict(lambda:0)\n",
        "for peptide in filtered_distinct['Peptide']:\n",
        "  for p in peptide:\n",
        "    if p not in ['-','.']:\n",
        "      distribution[p] +=1\n",
        "\n",
        "distribution['C'] += 2000\n",
        "distribution"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>>,\n",
              "            {'A': 25869,\n",
              "             'C': 2094,\n",
              "             'D': 18353,\n",
              "             'E': 25556,\n",
              "             'F': 12941,\n",
              "             'G': 23597,\n",
              "             'H': 8038,\n",
              "             'I': 17489,\n",
              "             'K': 19009,\n",
              "             'L': 35909,\n",
              "             'M': 5864,\n",
              "             'N': 13659,\n",
              "             'P': 19234,\n",
              "             'Q': 17000,\n",
              "             'R': 13441,\n",
              "             'S': 23495,\n",
              "             'T': 18492,\n",
              "             'V': 23850,\n",
              "             'W': 3231,\n",
              "             'Y': 8735})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtGW6X1Nc6D3"
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "class Vocab:\n",
        "  def __init__(self, init_token, end_token, pad_token):\n",
        "    self.init_token = init_token\n",
        "    self.end_token = end_token\n",
        "    self.pad_token = pad_token\n",
        "    self.stoi = OrderedDict()\n",
        "    self.itos = OrderedDict() \n",
        "\n",
        "    self.stoi[init_token] = 0\n",
        "    self.stoi[end_token] = 1\n",
        "    self.stoi[pad_token] = 2\n",
        "    self.itos[0] = init_token\n",
        "    self.itos[1] = end_token\n",
        "    self.itos[2] = pad_token\n",
        "    self._NEXT = 3\n",
        "\n",
        "  def _get_next(self):\n",
        "    _next = self._NEXT \n",
        "    self._NEXT += 1\n",
        "    return _next\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.stoi)\n",
        "\n",
        "class PField:\n",
        "  def __init__(self, init_token = '<sos>', end_token = '<eos>', pad_token='<pad>'):\n",
        "    self.vocab = Vocab(init_token, end_token, pad_token)\n",
        "\n",
        "  def preprocess(self, sequence):\n",
        "    sequence = sequence.strip()\n",
        "    result = \"\"\n",
        "    for s in sequence:\n",
        "      if s not in ['.','-']:\n",
        "        result+=s\n",
        "    return result\n",
        "    \n",
        "  def build_vocab(self, dataframe, column):\n",
        "    for peptide in dataframe[column].unique():\n",
        "      peptide = self.preprocess(peptide)\n",
        "      for p in peptide:\n",
        "        if p not in self.vocab.stoi:\n",
        "           _next_token = self.vocab._get_next()\n",
        "           self.vocab.stoi[p] = _next_token\n",
        "           self.vocab.itos[_next_token] = p\n",
        "\n",
        "  def tokenize(self, sequence):\n",
        "    sequence = self.preprocess(sequence)\n",
        "    return [self.vocab.stoi[self.vocab.init_token]] + [self.vocab.stoi[s] for s in sequence] + [self.vocab.stoi[self.vocab.end_token]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSyVJ9TyitU1"
      },
      "source": [
        "FIELD = PField()\n",
        "FIELD.build_vocab(filtered,'Peptide')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_C-SWjD9m3v"
      },
      "source": [
        "weights = { FIELD.vocab.stoi[p]: 1/distribution[p] for p in distribution }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUllPWXk98aV"
      },
      "source": [
        "weight_sum = sum(weights.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq17iQUB8DJf"
      },
      "source": [
        "weight_mean = np.mean(list(weights.values()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJSeXmZH-4-h"
      },
      "source": [
        "weights[0] = weight_mean\n",
        "weights[1] = weight_mean\n",
        "weights[2] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp26fJZ8-LBU",
        "outputId": "e2848f2b-79f0-46b1-9f05-392cb89ed636"
      },
      "source": [
        "weights = { w: weights[w]/weight_sum for w in weights}\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.05,\n",
              " 1: 0.05,\n",
              " 2: 0.0,\n",
              " 3: 0.02146321019334736,\n",
              " 4: 0.0375179022016737,\n",
              " 5: 0.02114373683407531,\n",
              " 6: 0.021370433677700394,\n",
              " 7: 0.03691911000019739,\n",
              " 8: 0.026218057787911832,\n",
              " 9: 0.03896747728094399,\n",
              " 10: 0.02747660456016434,\n",
              " 11: 0.026528387789609982,\n",
              " 12: 0.01404322380162901,\n",
              " 13: 0.019732279053556744,\n",
              " 14: 0.028834017010274812,\n",
              " 15: 0.08599558722590317,\n",
              " 16: 0.027270069407997848,\n",
              " 17: 0.02966341902898213,\n",
              " 18: 0.019493529842386493,\n",
              " 19: 0.06273676579904157,\n",
              " 20: 0.057730752546387654,\n",
              " 21: 0.15607493763314645,\n",
              " 22: 0.2408204983250698}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm-gomPG-sHo"
      },
      "source": [
        "from scipy.ndimage.filters import gaussian_filter1d\n",
        "weights = [weights[w] for w in sorted(weights)]\n",
        "weights = gaussian_filter1d(weights, sigma=2)\n",
        "weights = gaussian_filter1d(weights, sigma=2)\n",
        "weights_tensor = torch.Tensor(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHnkTvFD7IyY"
      },
      "source": [
        "weights_tensor = weights_tensor.divide(weights_tensor.sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTHz75k67O7R",
        "outputId": "9336b670-802e-4cd6-8b77-3f85ac4bbe9d"
      },
      "source": [
        "weights_tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0305, 0.0296, 0.0282, 0.0268, 0.0258, 0.0254, 0.0254, 0.0257, 0.0259,\n",
              "        0.0260, 0.0262, 0.0267, 0.0279, 0.0299, 0.0328, 0.0367, 0.0424, 0.0508,\n",
              "        0.0626, 0.0776, 0.0937, 0.1076, 0.1158])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "19XRmUxfaPEc",
        "outputId": "1f58685f-6328-422e-bc00-94910bbcaa4b"
      },
      "source": [
        "filtered_distinct['Peptide'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'SRVVGNPFDSK'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWDNXM3uaG9c",
        "outputId": "dbdf0457-214e-49cf-e3c8-f1385dea9a36"
      },
      "source": [
        "FIELD.tokenize(filtered_distinct['Peptide'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 3, 4, 5, 5, 6, 7, 8, 9, 10, 3, 11, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkvknYCJNslb"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5RFzwVg9LrR"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "\n",
        "class PeptideDataset(Dataset):\n",
        "  def __init__(self, processed, field):\n",
        "    self.data = processed.sort_values(by='Peptide_Length')\n",
        "    self.data_len = len(processed)\n",
        "    self.field = field\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.data_len\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.data.iloc[idx]\n",
        "    mass, charge, spectrum, peptide = row['parent mass'], row['PrecursorCharge'], row['spectrum'].toarray(), row['Peptide']\n",
        "    y = self.field.tokenize(peptide)\n",
        "    y_len = len(y)\n",
        "    return mass, charge, spectrum, y, y_len\n",
        "\n",
        "class PaddingSorter:\n",
        "    def __init__(self, device, field):\n",
        "        self.device = device\n",
        "        self.field = field\n",
        "        \n",
        "    def sort_batch(self, mass, charge, spectrum, targets, lengths):\n",
        "        \"\"\"\n",
        "        Sort a minibatch by the length of the sequences with the longest sequences first\n",
        "        return the sorted batch targes and sequence lengths.\n",
        "        This way the output can be used by pack_padded_sequences(...)\n",
        "        \"\"\"\n",
        "        seq_lengths, perm_idx = lengths.sort(0, descending=True)\n",
        "        mass = mass[perm_idx]\n",
        "        charge = charge[perm_idx]\n",
        "        spectrum = spectrum[perm_idx]\n",
        "        target_tensor = targets[perm_idx]\n",
        "        return  mass, charge, spectrum, target_tensor, seq_lengths\n",
        "\n",
        "    def pad_and_sort_batch(self, DataLoaderBatch):\n",
        "        \"\"\"\n",
        "        DataLoaderBatch should be a list of (sequence, target, length) tuples...\n",
        "        Returns a padded tensor of sequences sorted from longest to shortest, \n",
        "        \"\"\"\n",
        "        batch_size = len(DataLoaderBatch)\n",
        "        batch_split = list(zip(*DataLoaderBatch))\n",
        "        mass, charge, spectrum, y, y_len = batch_split[0], batch_split[1], batch_split[2], batch_split[3], batch_split[4]\n",
        "\n",
        "        \n",
        "        max_trg_length = max(y_len)\n",
        "        padded_trgs = np.full((batch_size, max_trg_length),self.field.vocab.stoi[self.field.vocab.pad_token])\n",
        "        for i, l in enumerate(y_len):\n",
        "            padded_trgs[i, 0:l] = y[i][0:l]\n",
        "\n",
        "        mass, charge, spectrum, y, y_len = self.sort_batch(torch.tensor(mass),\n",
        "                                               torch.tensor(charge),\n",
        "                                               torch.tensor(spectrum),\n",
        "                                               torch.tensor(padded_trgs),\n",
        "                                               torch.tensor(y_len))\n",
        "        \n",
        "        return {'x': {'mass': mass.float().to(self.device), 'charge':charge.float().to(self.device),'spectrum':spectrum.float().to(self.device)}, \n",
        "                'y': y.long().to(self.device),\n",
        "                'y_len': y_len.long().to(self.device)}\n",
        "    \n",
        "    def __call__(self, batch):\n",
        "        return self.pad_and_sort_batch(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJb2UWc8fMEl"
      },
      "source": [
        "dataset = PeptideDataset(filtered_distinct, FIELD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHK7rHpbiDJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14cfdcc4-016f-4dce-cdf5-9f87c1baae6f"
      },
      "source": [
        "dataset.__len__()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26127"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iBki3jAUXO-",
        "outputId": "ace980fe-c218-4a8c-eda5-b8f4d79e0f4f"
      },
      "source": [
        "print(dataset.__getitem__(112))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(820.4939999999998, 2, array([[0., 0., 0., ..., 0., 0., 0.]]), [0, 12, 11, 10, 12, 9, 6, 11, 1], 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvuBjt49iArM"
      },
      "source": [
        "train_data,valid_data,test_data = torch.utils.data.random_split(dataset,[int(dataset.__len__()*0.8),\n",
        "                                                                         int(dataset.__len__()*0.1),\n",
        "                                                                         int(dataset.__len__()*0.1)+2],\n",
        "                                                                generator=torch.Generator().manual_seed(SEED)\n",
        "                                                                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atL8reC_exfM",
        "outputId": "2fb5d277-37af-466d-ee4c-f459bde13f65"
      },
      "source": [
        "print(train_data.__getitem__(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1076.62, 2, array([[0., 0., 0., ..., 0., 0., 0.]]), [0, 12, 3, 3, 21, 5, 12, 12, 15, 11, 1], 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpjhyQasfNov"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 1024\n",
        "train_loader = DataLoader(train_data,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            shuffle=True,\n",
        "                            collate_fn=PaddingSorter(device,FIELD))\n",
        "valid_loader = DataLoader(valid_data,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            shuffle=True,\n",
        "                            collate_fn=PaddingSorter(device,FIELD))\n",
        "test_loader = DataLoader(test_data,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            shuffle=False,\n",
        "                            collate_fn=PaddingSorter(device,FIELD))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ctGgjsAXIAs",
        "outputId": "a236e227-3ecd-4147-ac42-ca69c6fa66d4"
      },
      "source": [
        "next(iter(train_loader))['x']['charge'].shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxV83-5wB1FT"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder,self).__init__()\n",
        "    \n",
        "    self.convnet = nn.Sequential(nn.Conv1d(1, 32, 100, 20),\n",
        "                                 nn.PReLU(),\n",
        "                                 nn.MaxPool1d(50, stride=2),\n",
        "                                 nn.Conv1d(32, 64, 5),\n",
        "                                 nn.PReLU(),\n",
        "                                 nn.MaxPool1d(2, stride=2))\n",
        "    self.pos_embedding = nn.Embedding(2051, 1)\n",
        "\n",
        "    self.linear = nn.Linear(640+1,256)\n",
        "\n",
        "  def forward(self,spectrum, charge):\n",
        "    spectrum = spectrum.to(device)\n",
        "    batch_size = spectrum.shape[0]\n",
        "\n",
        "    #create position tensor\n",
        "    pos = torch.arange(0, spectrum.shape[-1]).unsqueeze(0).repeat(batch_size, 1).to(device)\n",
        "        \n",
        "    #pos = [0, 1, 2, 3, ..., src len - 1]\n",
        "    pos_embedded = self.pos_embedding(pos)\n",
        "    \n",
        "    spectrum_with_pos = spectrum + pos_embedded.permute(0,2,1)\n",
        "   \n",
        "    convolved  = self.convnet(spectrum_with_pos.float())\n",
        "    \n",
        "    charge = torch.log(charge.float().to(device).unsqueeze(-1))\n",
        "    \n",
        "    convolved = convolved.view(convolved.size()[0],-1)\n",
        "\n",
        "    concatenated = torch.cat([convolved, charge],dim=-1)\n",
        "  \n",
        "    return self.linear(concatenated)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "  def __init__(self, output_dim, embedding_dim, spectral_linear_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.output_dim = output_dim\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_dim = dec_hid_dim\n",
        "    self.spectral_linear_dim = spectral_linear_dim\n",
        "    self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
        "    self.rnn = nn.GRU(enc_hid_dim + embedding_dim + spectral_linear_dim, dec_hid_dim)\n",
        "    self.fc_out = nn.Linear(dec_hid_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, prev_output, encoder_output, hidden):\n",
        "    \n",
        "    embedded_prev_output = self.dropout(self.embedding(prev_output))\n",
        "    \n",
        "    rnn_input = torch.cat((embedded_prev_output, encoder_output), dim = -1)\n",
        "\n",
        "    output, hidden = self.rnn(rnn_input.unsqueeze(0),hidden.unsqueeze(0))\n",
        "\n",
        "    output = self.fc_out(output)\n",
        "\n",
        "    return output.squeeze(0), hidden.squeeze(0)\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, device, freeze_encoder = True):\n",
        "    super(Seq2Seq,self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.linear = nn.Linear(2051, decoder.spectral_linear_dim)\n",
        "    self.decoder = decoder\n",
        "    self.device = device\n",
        "    if freeze_encoder:\n",
        "      for p in self.encoder.parameters():\n",
        "        p.requires_grad = False\n",
        "    \n",
        "  def forward(self, x, y, teacher_forcing_ratio = 0.5):\n",
        "    charge, spectrum = x['charge'], x['spectrum']\n",
        "    \n",
        "    batch_size = charge.shape[0]\n",
        "    trg_len = y.shape[1]\n",
        "\n",
        "    trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "    #tensor to store decoder outputs\n",
        "    outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "    #input passed through pretrained encoder\n",
        "    encoder_output = self.encoder(spectrum, charge)\n",
        "                \n",
        "    #first input to the decoder is the <sos> tokens\n",
        "    input = y[:,0]\n",
        "\n",
        "    spectrum = self.linear(spectrum).squeeze(1)\n",
        "\n",
        "    encoder_output = torch.cat([encoder_output, spectrum], dim= -1)\n",
        "    \n",
        "    hidden = torch.zeros((batch_size, self.decoder.hidden_dim)).to(self.device)\n",
        "\n",
        "                \n",
        "    for t in range(1, trg_len):\n",
        "      #insert input token embedding, previous hidden state, all encoder hidden states \n",
        "      #receive output tensor (predictions) and new hidden state\n",
        "      \n",
        "      output, hidden = self.decoder(input.squeeze(0), encoder_output, hidden)\n",
        "            \n",
        "      #place predictions in a tensor holding predictions for each token\n",
        "      outputs[t] = output\n",
        "            \n",
        "      #decide if we are going to use teacher forcing or not\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "      #get the highest predicted token from our predictions\n",
        "     \n",
        "      top1 = output.argmax(1) \n",
        "            \n",
        "      #if teacher forcing, use actual next token as next input\n",
        "      #if not, use predicted token\n",
        "      \n",
        "      input = y[:,t] if teacher_force else top1\n",
        "            \n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQWTmVTizMoy"
      },
      "source": [
        "ENCODER_NAME = 'encoder_siamese_cnn_stage2_2.pt'\n",
        "OUTPUT_DIM = len(FIELD.vocab)\n",
        "EMBEDDING_DIM = 256\n",
        "SPECTRAL_LINEAR_DIM = 128\n",
        "ENC_HID_DIM = 256\n",
        "DEC_HID_DIM = 256\n",
        "DROPOUT = 0.5\n",
        "encoder = Encoder()\n",
        "decoder = Decoder(OUTPUT_DIM, EMBEDDING_DIM,  SPECTRAL_LINEAR_DIM, ENC_HID_DIM, DEC_HID_DIM, DROPOUT)\n",
        "model = Seq2Seq(encoder, decoder, device, freeze_encoder=True).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLGS8H-jIp0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd40352f-8f3f-4835-f1b3-02e3cbedb222"
      },
      "source": [
        "for i, batch in enumerate(train_loader):\n",
        "  x, y = batch['x'], batch['y']\n",
        "  print(encoder(x['spectrum'], x['charge']))\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2057,  0.1825, -0.1982,  ..., -0.2993,  0.7617, -0.0275],\n",
            "        [ 0.2040,  0.1823, -0.2011,  ..., -0.3026,  0.7597, -0.0243],\n",
            "        [ 0.2058,  0.1839, -0.1966,  ..., -0.2959,  0.7595, -0.0272],\n",
            "        ...,\n",
            "        [ 0.2071,  0.1827, -0.2004,  ..., -0.3000,  0.7611, -0.0281],\n",
            "        [ 0.2054,  0.1835, -0.2001,  ..., -0.3020,  0.7626, -0.0269],\n",
            "        [ 0.2047,  0.1838, -0.2003,  ..., -0.2988,  0.7635, -0.0257]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We6vtv_oKQRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab47b1a-ef03-4bad-a4b3-f33a9299d3f5"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 964,119 trainable parameters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (convnet): Sequential(\n",
              "      (0): Conv1d(1, 32, kernel_size=(100,), stride=(20,))\n",
              "      (1): PReLU(num_parameters=1)\n",
              "      (2): MaxPool1d(kernel_size=50, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,))\n",
              "      (4): PReLU(num_parameters=1)\n",
              "      (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (pos_embedding): Embedding(2051, 1)\n",
              "    (linear): Linear(in_features=641, out_features=256, bias=True)\n",
              "  )\n",
              "  (linear): Linear(in_features=2051, out_features=128, bias=True)\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(23, 256)\n",
              "    (rnn): GRU(640, 256)\n",
              "    (fc_out): Linear(in_features=256, out_features=23, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZprWdg39B2X9",
        "outputId": "35b87fb3-fe34-4eca-8691-d9059fae2178"
      },
      "source": [
        "model.encoder.load_state_dict(torch.load(ENCODER_NAME, map_location=device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 378
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyqerBCzPaON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "924d9e9d-fc87-445c-88b8-e465bed24352"
      },
      "source": [
        "sample = next(iter(train_loader))\n",
        "output  = model(sample['x'],sample['y'])\n",
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([35, 1024, 23])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 379
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOdgnlAJL_BZ",
        "outputId": "2a1e74c5-5e90-4b04-a6db-c452c98bcc12"
      },
      "source": [
        "output[1:].shape\n",
        "\n",
        "#trg = [trg len, batch size]\n",
        "#output = [trg len, batch size, output dim]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([34, 1024, 23])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 380
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVJs8oftLvNa",
        "outputId": "256f4e57-1668-4670-96f2-b489762ada9e"
      },
      "source": [
        "sample['y'][...,1:].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1024, 34])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 381
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5CDMpPgD5cs"
      },
      "source": [
        "TRG_PAD_IDX = FIELD.vocab.stoi[FIELD.vocab.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX, \n",
        "                                weight=weights_tensor.to(device)\n",
        "                                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CMci2qNIUj5"
      },
      "source": [
        "N_EPOCHS = 40\n",
        "CLIP = 1\n",
        "RUN_NAME= 'seq2seq_1'\n",
        "MODEL_NAME = RUN_NAME+'.pt'\n",
        "def init_wandb(model,config,run_name):\n",
        "    wandb.init(project=\"cse291c00_seq2seq\",name=run_name,config=config)\n",
        "    #try:\n",
        "    #    wandb.watch(model)\n",
        "    #except:\n",
        "    #    print(\"Model already under watch!\")\n",
        "\n",
        "config = dict({\n",
        "    'model_type':'gru',\n",
        "    'seed':SEED,\n",
        "    'n_epochs':N_EPOCHS,\n",
        "    'clip':CLIP,\n",
        "    'batch size': BATCH_SIZE,\n",
        "    'trainable params': count_parameters(model),\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVmTg_JDLcop"
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeesxKB4Iwib"
      },
      "source": [
        "def train(model, optimizer, criterion, train_dataloader, device, clip):\n",
        "  model.train()\n",
        "  epoch_loss = 0.0\n",
        "  for i, batch in enumerate(train_dataloader):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    x, y_true = batch['x'], batch['y'].to(device)\n",
        "\n",
        "    output = model(x, y_true)\n",
        "    \n",
        "    output_dim = output.shape[-1]\n",
        "        \n",
        "    output = output[1:].view(-1, output_dim)\n",
        "\n",
        "    y_true = y_true.permute(1,0)\n",
        "\n",
        "    trg = y_true[1:].contiguous().view(-1)\n",
        "\n",
        "\n",
        "    #print(trg.shape)\n",
        "    #print(output.shape)\n",
        "\n",
        "    loss = criterion(output,trg)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.decoder.parameters(), clip)\n",
        "\n",
        "    optimizer.step()\n",
        "      \n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  return epoch_loss/len(train_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t24MSfvG0zOU"
      },
      "source": [
        "def evaluate(model, criterion, valid_dataloader, device):\n",
        "    \n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for i, batch in enumerate(valid_dataloader):\n",
        "\n",
        "       x, y_true = batch['x'], batch['y'].to(device)\n",
        "       \n",
        "       output = model(x, y_true)\n",
        "       \n",
        "       output_dim = output.shape[-1]\n",
        "        \n",
        "       output = output[1:].view(-1, output_dim)\n",
        "\n",
        "       y_true = y_true.permute(1,0)\n",
        "       trg = y_true[1:].contiguous().view(-1)\n",
        "\n",
        "       loss = criterion(output, trg)\n",
        "\n",
        "       epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss/len(valid_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPm2YwFzjQZi"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxdC_y8mk9J9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7fb90015bb9d4ab6b72dfe655dafaffd",
            "78d0ee724a4a4322892c0b285723b77a",
            "5a22af0a33054971bc65b35dbc12ff80",
            "ae33df0336444d928b44e4d5328a490e",
            "ee4087581bc94d61bd943945c2624995",
            "bb4745ca61494b55ab961303ce1b8fab",
            "1d481c2633cc4b44a210de0bb956264a",
            "7f324a890a1d4508b4e9beb0e857f3d4"
          ]
        },
        "outputId": "72dbff3d-e7ee-42ab-c72f-3563c8072a1c"
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "init_wandb(model,config,RUN_NAME)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, optimizer, criterion, train_loader, device, CLIP)\n",
        "    valid_loss = evaluate(model, criterion, valid_loader, device)\n",
        "    scheduler.step(valid_loss)\n",
        "    wandb.log({'epoch_loss':{\n",
        "                    'epoch':epoch,\n",
        "                    'train':{\n",
        "                        'loss':train_loss\n",
        "                    },\n",
        "                    'eval':{\n",
        "                        'loss':valid_loss\n",
        "                    }\n",
        "             }})\n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_NAME)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.5f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.5f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:3gt7y7uk) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 1807<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fb90015bb9d4ab6b72dfe655dafaffd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/drive/.shortcut-targets-by-id/1_O2YlSpkQTkWjTz-eA55kIq2rufipnHk/CSE291C00/Stage_1_Analysis_29_tissues_Project/wandb/run-20210526_034353-3gt7y7uk/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/drive/.shortcut-targets-by-id/1_O2YlSpkQTkWjTz-eA55kIq2rufipnHk/CSE291C00/Stage_1_Analysis_29_tissues_Project/wandb/run-20210526_034353-3gt7y7uk/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>403</td></tr><tr><td>_timestamp</td><td>1622001040</td></tr><tr><td>_step</td><td>39</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">seq2seq_1</strong>: <a href=\"https://wandb.ai/tanmaylaud/cse291c00_seq2seq/runs/3gt7y7uk\" target=\"_blank\">https://wandb.ai/tanmaylaud/cse291c00_seq2seq/runs/3gt7y7uk</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:3gt7y7uk). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">seq2seq_1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/tanmaylaud/cse291c00_seq2seq\" target=\"_blank\">https://wandb.ai/tanmaylaud/cse291c00_seq2seq</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/tanmaylaud/cse291c00_seq2seq/runs/3fow3lac\" target=\"_blank\">https://wandb.ai/tanmaylaud/cse291c00_seq2seq/runs/3fow3lac</a><br/>\n",
              "                Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1_O2YlSpkQTkWjTz-eA55kIq2rufipnHk/CSE291C00/Stage_1_Analysis_29_tissues_Project/wandb/run-20210526_042749-3fow3lac</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 10s\n",
            "\tTrain Loss: 2.99821 | Train PPL:  20.050\n",
            "\t Val. Loss: 2.89379 |  Val. PPL:  18.062\n",
            "Epoch: 02 | Time: 0m 9s\n",
            "\tTrain Loss: 2.86357 | Train PPL:  17.524\n",
            "\t Val. Loss: 2.81100 |  Val. PPL:  16.627\n",
            "Epoch: 03 | Time: 0m 10s\n",
            "\tTrain Loss: 2.76966 | Train PPL:  15.953\n",
            "\t Val. Loss: 2.72941 |  Val. PPL:  15.324\n",
            "Epoch: 04 | Time: 0m 10s\n",
            "\tTrain Loss: 2.73348 | Train PPL:  15.386\n",
            "\t Val. Loss: 2.71324 |  Val. PPL:  15.078\n",
            "Epoch: 05 | Time: 0m 10s\n",
            "\tTrain Loss: 2.70599 | Train PPL:  14.969\n",
            "\t Val. Loss: 2.69034 |  Val. PPL:  14.737\n",
            "Epoch: 06 | Time: 0m 10s\n",
            "\tTrain Loss: 2.67460 | Train PPL:  14.506\n",
            "\t Val. Loss: 2.66449 |  Val. PPL:  14.361\n",
            "Epoch: 07 | Time: 0m 10s\n",
            "\tTrain Loss: 2.65495 | Train PPL:  14.224\n",
            "\t Val. Loss: 2.67055 |  Val. PPL:  14.448\n",
            "Epoch: 08 | Time: 0m 10s\n",
            "\tTrain Loss: 2.64611 | Train PPL:  14.099\n",
            "\t Val. Loss: 2.65416 |  Val. PPL:  14.213\n",
            "Epoch: 09 | Time: 0m 9s\n",
            "\tTrain Loss: 2.64995 | Train PPL:  14.153\n",
            "\t Val. Loss: 2.67210 |  Val. PPL:  14.470\n",
            "Epoch: 10 | Time: 0m 10s\n",
            "\tTrain Loss: 2.63660 | Train PPL:  13.966\n",
            "\t Val. Loss: 2.64612 |  Val. PPL:  14.099\n",
            "Epoch: 11 | Time: 0m 10s\n",
            "\tTrain Loss: 2.62236 | Train PPL:  13.768\n",
            "\t Val. Loss: 2.64257 |  Val. PPL:  14.049\n",
            "Epoch: 12 | Time: 0m 9s\n",
            "\tTrain Loss: 2.61038 | Train PPL:  13.604\n",
            "\t Val. Loss: 2.63314 |  Val. PPL:  13.917\n",
            "Epoch: 13 | Time: 0m 10s\n",
            "\tTrain Loss: 2.60477 | Train PPL:  13.528\n",
            "\t Val. Loss: 2.63834 |  Val. PPL:  13.990\n",
            "Epoch: 14 | Time: 0m 10s\n",
            "\tTrain Loss: 2.60569 | Train PPL:  13.541\n",
            "\t Val. Loss: 2.62644 |  Val. PPL:  13.824\n",
            "Epoch: 15 | Time: 0m 10s\n",
            "\tTrain Loss: 2.59723 | Train PPL:  13.426\n",
            "\t Val. Loss: 2.62177 |  Val. PPL:  13.760\n",
            "Epoch: 16 | Time: 0m 10s\n",
            "\tTrain Loss: 2.58726 | Train PPL:  13.293\n",
            "\t Val. Loss: 2.62128 |  Val. PPL:  13.753\n",
            "Epoch: 17 | Time: 0m 9s\n",
            "\tTrain Loss: 2.57893 | Train PPL:  13.183\n",
            "\t Val. Loss: 2.59740 |  Val. PPL:  13.429\n",
            "Epoch: 18 | Time: 0m 10s\n",
            "\tTrain Loss: 2.57033 | Train PPL:  13.070\n",
            "\t Val. Loss: 2.61206 |  Val. PPL:  13.627\n",
            "Epoch: 19 | Time: 0m 9s\n",
            "\tTrain Loss: 2.57391 | Train PPL:  13.117\n",
            "\t Val. Loss: 2.60468 |  Val. PPL:  13.527\n",
            "Epoch: 20 | Time: 0m 9s\n",
            "\tTrain Loss: 2.57537 | Train PPL:  13.136\n",
            "\t Val. Loss: 2.59982 |  Val. PPL:  13.461\n",
            "Epoch: 21 | Time: 0m 9s\n",
            "\tTrain Loss: 2.55961 | Train PPL:  12.931\n",
            "\t Val. Loss: 2.58135 |  Val. PPL:  13.215\n",
            "Epoch: 22 | Time: 0m 10s\n",
            "\tTrain Loss: 2.55521 | Train PPL:  12.874\n",
            "\t Val. Loss: 2.58577 |  Val. PPL:  13.274\n",
            "Epoch: 23 | Time: 0m 10s\n",
            "\tTrain Loss: 2.54553 | Train PPL:  12.750\n",
            "\t Val. Loss: 2.58732 |  Val. PPL:  13.294\n",
            "Epoch: 24 | Time: 0m 10s\n",
            "\tTrain Loss: 2.54806 | Train PPL:  12.782\n",
            "\t Val. Loss: 2.56842 |  Val. PPL:  13.045\n",
            "Epoch: 25 | Time: 0m 10s\n",
            "\tTrain Loss: 2.53675 | Train PPL:  12.638\n",
            "\t Val. Loss: 2.57071 |  Val. PPL:  13.075\n",
            "Epoch: 26 | Time: 0m 10s\n",
            "\tTrain Loss: 2.53300 | Train PPL:  12.591\n",
            "\t Val. Loss: 2.59953 |  Val. PPL:  13.457\n",
            "Epoch: 27 | Time: 0m 10s\n",
            "\tTrain Loss: 2.53069 | Train PPL:  12.562\n",
            "\t Val. Loss: 2.58375 |  Val. PPL:  13.247\n",
            "Epoch: 28 | Time: 0m 10s\n",
            "\tTrain Loss: 2.52363 | Train PPL:  12.474\n",
            "\t Val. Loss: 2.56955 |  Val. PPL:  13.060\n",
            "Epoch: 29 | Time: 0m 10s\n",
            "\tTrain Loss: 2.51918 | Train PPL:  12.418\n",
            "\t Val. Loss: 2.56407 |  Val. PPL:  12.989\n",
            "Epoch: 30 | Time: 0m 10s\n",
            "\tTrain Loss: 2.50953 | Train PPL:  12.299\n",
            "\t Val. Loss: 2.55812 |  Val. PPL:  12.911\n",
            "Epoch: 31 | Time: 0m 10s\n",
            "\tTrain Loss: 2.50662 | Train PPL:  12.263\n",
            "\t Val. Loss: 2.56132 |  Val. PPL:  12.953\n",
            "Epoch: 32 | Time: 0m 9s\n",
            "\tTrain Loss: 2.50875 | Train PPL:  12.290\n",
            "\t Val. Loss: 2.57042 |  Val. PPL:  13.071\n",
            "Epoch: 33 | Time: 0m 10s\n",
            "\tTrain Loss: 2.49716 | Train PPL:  12.148\n",
            "\t Val. Loss: 2.57482 |  Val. PPL:  13.129\n",
            "Epoch: 34 | Time: 0m 10s\n",
            "\tTrain Loss: 2.49190 | Train PPL:  12.084\n",
            "\t Val. Loss: 2.55264 |  Val. PPL:  12.841\n",
            "Epoch: 35 | Time: 0m 10s\n",
            "\tTrain Loss: 2.48950 | Train PPL:  12.055\n",
            "\t Val. Loss: 2.56377 |  Val. PPL:  12.985\n",
            "Epoch: 36 | Time: 0m 10s\n",
            "\tTrain Loss: 2.48518 | Train PPL:  12.003\n",
            "\t Val. Loss: 2.56754 |  Val. PPL:  13.034\n",
            "Epoch: 37 | Time: 0m 10s\n",
            "\tTrain Loss: 2.47945 | Train PPL:  11.935\n",
            "\t Val. Loss: 2.59000 |  Val. PPL:  13.330\n",
            "Epoch: 38 | Time: 0m 10s\n",
            "\tTrain Loss: 2.47637 | Train PPL:  11.898\n",
            "\t Val. Loss: 2.56206 |  Val. PPL:  12.963\n",
            "Epoch: 39 | Time: 0m 9s\n",
            "\tTrain Loss: 2.45956 | Train PPL:  11.700\n",
            "\t Val. Loss: 2.55086 |  Val. PPL:  12.818\n",
            "Epoch: 40 | Time: 0m 10s\n",
            "\tTrain Loss: 2.45665 | Train PPL:  11.666\n",
            "\t Val. Loss: 2.57294 |  Val. PPL:  13.104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7hSqfbVIIX8",
        "outputId": "d51d82c8-ef44-4aee-ff50-1607ac863c9d"
      },
      "source": [
        "model.load_state_dict(torch.load(MODEL_NAME, map_location=device))\n",
        "\n",
        "test_loss = evaluate(model, criterion, test_loader, device)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 2.559 | Test PPL:  12.928 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_7Md8_COlQ9"
      },
      "source": [
        "class Beam:\n",
        "    def __init__(self, prob, token_index, hidden, prev = None):\n",
        "        self.prob = prob\n",
        "        self.token_index = token_index\n",
        "        self.hidden = hidden\n",
        "        self.prev = prev\n",
        "\n",
        "    def flatten(self):\n",
        "        beam_list = []\n",
        "        curr = self\n",
        "        while curr is not None:\n",
        "            #print(\"Insert beam...\")\n",
        "            beam_list.insert(0,curr)\n",
        "            curr = curr.prev\n",
        "        return beam_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tXA52JHOs8A"
      },
      "source": [
        "def beam_search_torch(model, device, hidden, encoder_outputs, beam_width, max_len, trg_field, beam_penalty):\n",
        "    model.eval()\n",
        "    initial_token_index = trg_field.vocab.stoi[trg_field.vocab.init_token]\n",
        "    initial_beam = Beam(torch.tensor(1),initial_token_index, hidden)\n",
        "    queue = []\n",
        "    targets = []\n",
        "    VOCAB_SIZE = len(trg_field.vocab)\n",
        "    HIDDEN_SIZE = hidden.size(1)\n",
        "    queue.append(initial_beam)\n",
        "    while len(queue)!= 0 and max_len != 0:\n",
        "        size = len(queue)\n",
        "        candidates = torch.zeros(size, VOCAB_SIZE).to(device)\n",
        "        hidden_states = torch.zeros(size, HIDDEN_SIZE).to(device)\n",
        "        beams  = []\n",
        "        #print(f\"Current beam size:{size}\")\n",
        "        #print(\"Looking for candidates...\")\n",
        "        for i in range(0,size):\n",
        "            beam = queue.pop()\n",
        "            with torch.no_grad():\n",
        "                trg_tensor = torch.LongTensor([beam.token_index]).to(device)\n",
        "                #print(beam.hidden.view(1,-1).shape)\n",
        "                output, hidden = model.decoder(trg_tensor, encoder_outputs, beam.hidden.view(1,-1))\n",
        "                output = torch.nn.functional.log_softmax(output,-1)\n",
        "            candidates[i] = output + beam.prob \n",
        "            hidden_states[i] = hidden\n",
        "            beams.append(beam)\n",
        "       \n",
        "        probs, token_indices = torch.topk(candidates.view(-1), beam_width)\n",
        "        #print(probs)\n",
        "        beam_ids =  token_indices//VOCAB_SIZE\n",
        "        indices = token_indices.fmod(VOCAB_SIZE)\n",
        "        #print(indices)\n",
        "        #print([trg_field.vocab.itos[index] for index in indices])\n",
        "        #print(f\"Found {len(candidates)} top candidates...\")\n",
        "        for i in range(0,beam_width):\n",
        "            prev_beam = beams[beam_ids[i]]\n",
        "            prob, token_index, hidden = probs[i],indices[i], hidden_states[beam_ids[i]]\n",
        "            #print(trg_field.vocab.itos[token_index],end=',')\n",
        "            beam = Beam(prob, token_index.item(), hidden, prev_beam)\n",
        "            if token_index.item() == trg_field.vocab.stoi[trg_field.vocab.end_token]:\n",
        "                targets.append(beam)\n",
        "                #print(f\"Adding beam to targets...\")\n",
        "            else:\n",
        "                queue.append(beam)    \n",
        "        max_len -= 1\n",
        "                        \n",
        "    if len(targets) ==0:\n",
        "        print('WARNING: No <eos> found')\n",
        "        for i in range(0,len(queue)):\n",
        "            targets.append(queue.pop())\n",
        "        \n",
        "    best_beam = None\n",
        "    max_prob  = float('-inf')\n",
        "   \n",
        "    #print('Len of targets:',len(targets))\n",
        "    for i in range(0,len(targets)):\n",
        "        \n",
        "        beam = targets[i].flatten()\n",
        "        #print([trg_field.vocab.itos[i.token_index] for i in beam[1:]])\n",
        "\n",
        "        if beam[-1].prob > max_prob:\n",
        "            max_prob = beam[-1].prob\n",
        "            best_beam = beam\n",
        "    #print(max_prob)       \n",
        "    trg_tokens = [trg_field.vocab.itos[i.token_index] for i in best_beam]\n",
        "    return trg_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_gn3frtO5ee"
      },
      "source": [
        "def compute_beam(model,x, field, device, max_len = 30, beam_width = 10, beam_penalty = 1.0):\n",
        "  model.eval()\n",
        "  \n",
        "  charge, spectrum = x['charge'], x['spectrum']\n",
        "    \n",
        "  trg_vocab_size = model.decoder.output_dim\n",
        "  \n",
        "  with torch.no_grad():      \n",
        "    #input passed through pretrained encoder\n",
        "    encoder_output = model.encoder(spectrum, charge)\n",
        "    spectrum = model.linear(spectrum).squeeze(1)\n",
        "    encoder_output = torch.cat([encoder_output, spectrum], dim= -1)           \n",
        "    #first input to the decoder is the <sos> tokens\n",
        "    \n",
        "    hidden = torch.zeros((1, model.decoder.hidden_dim)).to(device)\n",
        "      \n",
        "  return beam_search_torch(model, device, hidden, encoder_output, beam_width, max_len, field, beam_penalty)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eAJbzypTnHF"
      },
      "source": [
        "def compute_sequence(model, x, field, device, max_len = 40):\n",
        "  model.eval()\n",
        "  \n",
        "  charge, spectrum = x['charge'], x['spectrum']\n",
        "    \n",
        "  trg_vocab_size = model.decoder.output_dim\n",
        "  \n",
        "  outputs = []\n",
        "  with torch.no_grad():      \n",
        "    #input passed through pretrained encoder\n",
        "    encoder_output = model.encoder(spectrum, charge)\n",
        "    spectrum = model.linear(spectrum).squeeze(1)\n",
        "    encoder_output = torch.cat([encoder_output, spectrum], dim= -1)           \n",
        "    #first input to the decoder is the <sos> tokens\n",
        "    \n",
        "    hidden = torch.zeros((1, model.decoder.hidden_dim)).to(device)\n",
        "    outputs.append(field.vocab.stoi[field.vocab.init_token])\n",
        "\n",
        "    for t in range(0, max_len):\n",
        "      #insert input token embedding, previous hidden state, all encoder hidden states \n",
        "      #receive output tensor (predictions) and new hidden state\n",
        "      #print(encoder_output.shape)\n",
        "      #print(input.shape)\n",
        "      input = torch.tensor(outputs[-1]).to(device)\n",
        "      #print(input)\n",
        "      output, hidden = model.decoder(input.unsqueeze(0), encoder_output, hidden)\n",
        "                \n",
        "      #get the highest predicted token from our predictions\n",
        "      trg_index = output.argmax(1).item()\n",
        "      #print(trg_index.shape)\n",
        "      outputs.append(trg_index)\n",
        "      if trg_index == field.vocab.stoi[field.vocab.end_token]:\n",
        "        break \n",
        "        \n",
        "  return [field.vocab.itos[token] for token in outputs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA1zL8cjXEPI"
      },
      "source": [
        "example_loader = DataLoader(test_data,\n",
        "                            batch_size=1,\n",
        "                            shuffle=False,\n",
        "                            collate_fn=PaddingSorter(device,FIELD))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUX2fp_jWtAx"
      },
      "source": [
        "itera = iter(example_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjGkL010kKB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfe567eb-ffc0-4db7-fda6-88464b826822"
      },
      "source": [
        "example = next(itera)\n",
        "src = example['x']\n",
        "trg = [FIELD.vocab.itos[token.item()] for token in example['y'][0]]\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "print(f'prd = {compute_sequence(model, src, FIELD, device)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = {'mass': tensor([1550.6899], device='cuda:0'), 'charge': tensor([2.], device='cuda:0'), 'spectrum': tensor([[[0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')}\n",
            "trg = ['<sos>', 'Y', 'L', 'T', 'D', 'S', 'E', 'Y', 'T', 'E', 'G', 'S', 'T', 'G', 'K', '<eos>']\n",
            "prd = ['<sos>', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'R', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUfSXKwWcXZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d920520a-9d50-4232-e8a9-301a435ef73b"
      },
      "source": [
        "example = next(itera)\n",
        "src = example['x']\n",
        "trg = [FIELD.vocab.itos[token.item()] for token in example['y'][0]]\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "print(f'prd = {compute_beam(model, src, FIELD, device, max_len = 30, beam_width=5, beam_penalty=1)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = {'mass': tensor([1079.5400], device='cuda:0'), 'charge': tensor([2.], device='cuda:0'), 'spectrum': tensor([[[0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')}\n",
            "trg = ['<sos>', 'K', 'D', 'L', 'G', 'E', 'E', 'N', 'F', 'K', '<eos>']\n",
            "prd = ['<sos>', 'T', 'F', 'E', 'E', 'H', 'H', 'E', 'K', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqlFfaEu2Lr4"
      },
      "source": [
        "max_score = 0\n",
        "sequence = {}\n",
        "for i, example in enumerate(example_loader):\n",
        "  #print(example)\n",
        "  src = example['x']\n",
        "  trg = [FIELD.vocab.itos[token.item()] for token in example['y'][0]]\n",
        "  trg = trg[1:-1]\n",
        "  pred = compute_sequence(model, src, FIELD, device)\n",
        "  pred = pred[1:-1]\n",
        "  # print(f'src = {src}')\n",
        "  # print(f'trg = {trg}')\n",
        "  # print(f'prd = {pred}')\n",
        "\n",
        "  score = bleu_score([pred], [[trg]], max_n = 2, weights = [0.5,0.5])*100\n",
        "  sequence[score] = [\"\".join(trg),\"\".join(pred)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bmwVkgg47KA"
      },
      "source": [
        "keys = sorted(sequence, reverse = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTWTellg5Fk2"
      },
      "source": [
        "import pandas as pd\n",
        "result = pd.DataFrame(sequence).T.reset_index().sort_values(by=\"index\",ascending=False)\n",
        "result.columns = ['score', 'Target', 'Predicted']\n",
        "results = result.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W356tBm19O2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "bc675fcc-72ce-4118-f2b9-39a59211e761"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>Target</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>59.628481</td>\n",
              "      <td>LLEEYTQLAR</td>\n",
              "      <td>LLEEAQQLLR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>57.772983</td>\n",
              "      <td>LEAALGEAK</td>\n",
              "      <td>LLEALLAK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>52.440441</td>\n",
              "      <td>LIETELLQLTQLELK</td>\n",
              "      <td>LLLEEALQQQLQLLLK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>45.643547</td>\n",
              "      <td>LQQLQMEK</td>\n",
              "      <td>AQQQLQAAK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>45.291084</td>\n",
              "      <td>AKPAEAPAAAAPK</td>\n",
              "      <td>AAAAAAAAAAAAK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>43.643579</td>\n",
              "      <td>NQLLAER</td>\n",
              "      <td>QQLLLLR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>42.365927</td>\n",
              "      <td>LLLEFTDTSYEEK</td>\n",
              "      <td>LLLEEEYLYYYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>42.257714</td>\n",
              "      <td>VLLEAAIR</td>\n",
              "      <td>LLLLAAAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>41.931397</td>\n",
              "      <td>LENLLLLDLQHNR</td>\n",
              "      <td>LLLELHLHLHLLAK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>41.408979</td>\n",
              "      <td>AEEYEFLTPVEEAPK</td>\n",
              "      <td>ALYYEEEEAAAAAK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>40.851669</td>\n",
              "      <td>NEALAALLR</td>\n",
              "      <td>QLLLQAAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>40.102208</td>\n",
              "      <td>LQQQLTQAAQELAAEKEK</td>\n",
              "      <td>ALLQALQHLQQLQQLQALR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>39.458706</td>\n",
              "      <td>QLLLIAGLTR</td>\n",
              "      <td>AQLLQLQLR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>38.188133</td>\n",
              "      <td>KLNQALLDLHALGSAR</td>\n",
              "      <td>ALHHHHHQAHAAAAAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>37.796450</td>\n",
              "      <td>AAIGLLAR</td>\n",
              "      <td>AAAAAAAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>37.292302</td>\n",
              "      <td>KLGAQLEAR</td>\n",
              "      <td>TQEAAAAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>37.267798</td>\n",
              "      <td>TINQLLAER</td>\n",
              "      <td>LLLQALAAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>36.939832</td>\n",
              "      <td>KEGDLIAAQAR</td>\n",
              "      <td>QQQAAAAAAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>36.927450</td>\n",
              "      <td>ELLLQPVTISR</td>\n",
              "      <td>LLEELQQLQQLR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>36.927447</td>\n",
              "      <td>IQQQQPPPGEK</td>\n",
              "      <td>QQQQQQQQQQK</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         score              Target            Predicted\n",
              "217  59.628481          LLEEYTQLAR           LLEEAQQLLR\n",
              "303  57.772983           LEAALGEAK             LLEALLAK\n",
              "192  52.440441     LIETELLQLTQLELK     LLLEEALQQQLQLLLK\n",
              "104  45.643547            LQQLQMEK            AQQQLQAAK\n",
              "87   45.291084       AKPAEAPAAAAPK        AAAAAAAAAAAAK\n",
              "79   43.643579             NQLLAER              QQLLLLR\n",
              "288  42.365927       LLLEFTDTSYEEK        LLLEEEYLYYYYY\n",
              "55   42.257714            VLLEAAIR             LLLLAAAR\n",
              "204  41.931397       LENLLLLDLQHNR       LLLELHLHLHLLAK\n",
              "305  41.408979     AEEYEFLTPVEEAPK       ALYYEEEEAAAAAK\n",
              "286  40.851669           NEALAALLR             QLLLQAAR\n",
              "306  40.102208  LQQQLTQAAQELAAEKEK  ALLQALQHLQQLQQLQALR\n",
              "184  39.458706          QLLLIAGLTR            AQLLQLQLR\n",
              "250  38.188133    KLNQALLDLHALGSAR     ALHHHHHQAHAAAAAR\n",
              "282  37.796450            AAIGLLAR             AAAAAAAR\n",
              "31   37.292302           KLGAQLEAR             TQEAAAAR\n",
              "49   37.267798           TINQLLAER            LLLQALAAR\n",
              "213  36.939832         KEGDLIAAQAR           QQQAAAAAAR\n",
              "201  36.927450         ELLLQPVTISR         LLEELQQLQQLR\n",
              "235  36.927447         IQQQQPPPGEK          QQQQQQQQQQK"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tWkwwcg79jM"
      },
      "source": [
        "results.to_csv('Sequence_Results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0Dqqdx04fE6",
        "outputId": "6e8da4ac-70ad-4d03-f4e6-8d56611f025b"
      },
      "source": [
        "sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'charge': tensor([2.], device='cuda:0'),\n",
              "  'mass': tensor([1235.6700], device='cuda:0'),\n",
              "  'spectrum': tensor([[[0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')},\n",
              " ['<sos>', 'L', 'L', 'E', 'E', 'Y', 'T', 'Q', 'L', 'A', 'R', '<eos>'],\n",
              " ['<sos>', 'L', 'L', 'E', 'E', 'A', 'Q', 'Q', 'L', 'L', 'R', '<eos>']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiaCk4EdSQoz"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "def calculate_bleu(data, FIELD, model, device, max_len = 30, beam_width = 1, beam_penalty = 0.75):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    length_score = 0\n",
        "    for i, example in enumerate(data):\n",
        "        #print(example)\n",
        "        _, charge, spectrum, trg, _ = example\n",
        "        src = {'charge': torch.Tensor([charge]), 'spectrum': torch.Tensor(spectrum).to(device)}\n",
        "        trg = [FIELD.vocab.itos[token] for token in trg]\n",
        "        \n",
        "        pred_trg = compute_beam(model, src, FIELD, device, max_len, beam_width, beam_penalty)\n",
        "\n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "        length_score += int(np.abs(len(pred_trg)-len(trg)) <= 2)\n",
        "        if i % 300 == 0:\n",
        "          print(f'{i} Samples generated...')\n",
        "        if i > 1000:\n",
        "          print('Length score:',length_score*1.0*100/1001)\n",
        "          break  \n",
        "    #print(pred_trgs)\n",
        "    return bleu_score(pred_trgs, trgs, max_n=3, weights=[0.33,0.33,0.33])*100,bleu_score(pred_trgs, trgs, max_n=2, weights=[0.5,0.5])*100,bleu_score(pred_trgs, trgs, max_n=1, weights=[1])*100\n",
        "\n",
        "\n",
        "def calculate_bleu_random(data, FIELD):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    lengths = []\n",
        "    length_score = 0\n",
        "    for example in test_data:\n",
        "      lengths.append(example[-1])\n",
        "    min_len, max_len = np.min(lengths), np.max(lengths)\n",
        "    for i, example in enumerate(data):\n",
        "        _, _, _, trg, _ = example\n",
        "        trg = [FIELD.vocab.itos[token] for token in trg]\n",
        "        \n",
        "        pred_trg = [FIELD.vocab.itos[np.argmax(np.random.multinomial(1, weights_tensor.numpy()))] for i in range(0, np.random.randint(min_len, max_len+1))]\n",
        "\n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "        length_score += int(np.abs(len(pred_trg)-len(trg)) <= 2)\n",
        "        if i % 300 == 0:\n",
        "          print(f'{i} Samples generated...')\n",
        "        if i > 1000:\n",
        "          print('Length score:',length_score*1.0*100/1001)\n",
        "          break  \n",
        "    #print(pred_trgs)\n",
        "    return bleu_score(pred_trgs, trgs, max_n=3, weights=[0.33,0.33,0.33])*100,bleu_score(pred_trgs, trgs, max_n=2, weights=[0.5,0.5])*100,bleu_score(pred_trgs, trgs, max_n=1, weights=[1])*100\n",
        "\n",
        "def calculate_bleu_random_biased(data, FIELD):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    lengths = []\n",
        "    length_score = 0\n",
        "    for example in test_data:\n",
        "      lengths.append(example[-1])\n",
        "    min_len, max_len = np.min(lengths), np.max(lengths)\n",
        "    for i, example in enumerate(data):\n",
        "        _, _, _, trg, _ = example\n",
        "        trg = [FIELD.vocab.itos[token] for token in trg]\n",
        "        \n",
        "        pred_trg = [FIELD.vocab.itos[np.argmax(np.random.multinomial(1, weights_tensor.numpy()))] for i in range(0, len(trg)+1)]\n",
        "\n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "        length_score += int(np.abs(len(pred_trg)-len(trg)) <= 2)\n",
        "        if i % 300 == 0:\n",
        "          print(f'{i} Samples generated...')\n",
        "        if i > 1000:\n",
        "          print('Length score:',length_score*1.0*100/1001)\n",
        "          break  \n",
        "    #print(pred_trgs)\n",
        "    return bleu_score(pred_trgs, trgs, max_n=3, weights=[0.33,0.33,0.33])*100,bleu_score(pred_trgs, trgs, max_n=2, weights=[0.5,0.5])*100,bleu_score(pred_trgs, trgs, max_n=1, weights=[1])*100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ50lv8rZ9w2",
        "outputId": "3e9868e3-a03d-4741-8ad3-da77b9975ac4"
      },
      "source": [
        "calculate_bleu(test_data, FIELD, model, device, beam_width= 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Samples generated...\n",
            "300 Samples generated...\n",
            "600 Samples generated...\n",
            "900 Samples generated...\n",
            "Length score: 88.51148851148851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6.609015011238808, 16.646854788855133, 33.575250925547294)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 472
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PUl54dzeLJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2428cfce-2e18-4b85-80b6-7d979548bc86"
      },
      "source": [
        "calculate_bleu_random(test_data, FIELD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Samples generated...\n",
            "300 Samples generated...\n",
            "600 Samples generated...\n",
            "900 Samples generated...\n",
            "Length score: 14.385614385614385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.4184435829520226, 6.749681383371353, 26.696643233299255)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 473
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DfHYZs0B6Yq",
        "outputId": "9f1215f8-a0b5-4010-b13a-757faf785034"
      },
      "source": [
        "calculate_bleu_random_biased(test_data, FIELD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Samples generated...\n",
            "300 Samples generated...\n",
            "600 Samples generated...\n",
            "900 Samples generated...\n",
            "Length score: 100.0999000999001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.4717801474034786, 7.457941770553589, 31.34995698928833)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 474
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIfxoPAKCY4t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}